{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter \n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "import re\n",
    "\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset  (156060, 4)\n",
      "Index(['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], dtype='object')\n",
      "No. of unique classes 5\n"
     ]
    }
   ],
   "source": [
    "# reading data\n",
    "df = pd.read_table('train.tsv', encoding='latin')\n",
    "sentiment = [0,1,2,3,4,5]\n",
    "df = df[df.Sentiment.isin(sentiment)]\n",
    "df = df.dropna()\n",
    "lyrics = shuffle(df)\n",
    "lyrics = lyrics.reset_index(drop=True)\n",
    "print('Shape of dataset ',df.shape)\n",
    "print(df.columns)\n",
    "print('No. of unique classes',len(set(df['Sentiment'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics.drop(columns=['PhraseId','SentenceId'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lyrics.drop(columns=['artist_name','title','Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "    \n",
    "lyrics1 = MultiColumnLabelEncoder(columns = ['Sentiment']).fit_transform(lyrics)\n",
    "#lyrics1 = MultiColumnLabelEncoder(columns = ['song']).fit_transform(lyrics1)\n",
    "lyrics1.head()\n",
    "lyrics1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['0','1','2','3']\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "lyrics1.Sentiment.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c828b8d42558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mlyrics1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mlyrics1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c828b8d42558>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#text = BeautifulSoup(text, \"lxml\").text # HTML decoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# lowercase text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREPLACE_BY_SPACE_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# replace REPLACE_BY_SPACE_RE symbols by space in text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBAD_SYMBOLS_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# delete symbols which are in BAD_SYMBOLS_RE from text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    #text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "lyrics1['Sentiment'] = lyrics['Sentiment'].apply(clean_text)\n",
    "lyrics1['Sentiment'].apply(lambda x: len(x.split(' '))).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_timbre1</th>\n",
       "      <th>avg_timbre2</th>\n",
       "      <th>avg_timbre3</th>\n",
       "      <th>avg_timbre4</th>\n",
       "      <th>...</th>\n",
       "      <th>var_timbre5</th>\n",
       "      <th>var_timbre6</th>\n",
       "      <th>var_timbre7</th>\n",
       "      <th>var_timbre8</th>\n",
       "      <th>var_timbre9</th>\n",
       "      <th>var_timbre10</th>\n",
       "      <th>var_timbre11</th>\n",
       "      <th>var_timbre12</th>\n",
       "      <th>Mood</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.492</td>\n",
       "      <td>102.750</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>151.82322</td>\n",
       "      <td>44.942701</td>\n",
       "      <td>2.919043</td>\n",
       "      <td>11.452190</td>\n",
       "      <td>-9.939052</td>\n",
       "      <td>...</td>\n",
       "      <td>1002.359830</td>\n",
       "      <td>533.826713</td>\n",
       "      <td>450.342031</td>\n",
       "      <td>371.213158</td>\n",
       "      <td>401.667458</td>\n",
       "      <td>280.375637</td>\n",
       "      <td>164.954610</td>\n",
       "      <td>208.439259</td>\n",
       "      <td>3</td>\n",
       "      <td>meet boy like lot fall love loves flame start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14.124</td>\n",
       "      <td>47.873</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>278.28200</td>\n",
       "      <td>38.694596</td>\n",
       "      <td>-57.189799</td>\n",
       "      <td>13.145835</td>\n",
       "      <td>-14.565573</td>\n",
       "      <td>...</td>\n",
       "      <td>1068.480738</td>\n",
       "      <td>652.288168</td>\n",
       "      <td>620.755049</td>\n",
       "      <td>472.195177</td>\n",
       "      <td>438.343359</td>\n",
       "      <td>242.868357</td>\n",
       "      <td>288.765284</td>\n",
       "      <td>339.127532</td>\n",
       "      <td>3</td>\n",
       "      <td>dont know sky blue dont know im love music wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.541</td>\n",
       "      <td>129.161</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>140.27710</td>\n",
       "      <td>46.470737</td>\n",
       "      <td>72.100780</td>\n",
       "      <td>58.162805</td>\n",
       "      <td>3.429465</td>\n",
       "      <td>...</td>\n",
       "      <td>503.012331</td>\n",
       "      <td>1061.091441</td>\n",
       "      <td>1244.746517</td>\n",
       "      <td>423.583005</td>\n",
       "      <td>275.888234</td>\n",
       "      <td>257.913246</td>\n",
       "      <td>302.292429</td>\n",
       "      <td>359.757659</td>\n",
       "      <td>3</td>\n",
       "      <td>party ill cry want cry want cry want would cry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.842</td>\n",
       "      <td>116.031</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>449.27955</td>\n",
       "      <td>37.471401</td>\n",
       "      <td>-17.614596</td>\n",
       "      <td>-20.050936</td>\n",
       "      <td>-1.241322</td>\n",
       "      <td>...</td>\n",
       "      <td>755.294995</td>\n",
       "      <td>1170.909474</td>\n",
       "      <td>523.003044</td>\n",
       "      <td>510.947644</td>\n",
       "      <td>276.371599</td>\n",
       "      <td>321.595321</td>\n",
       "      <td>366.422585</td>\n",
       "      <td>272.122071</td>\n",
       "      <td>2</td>\n",
       "      <td>day expanding man shape shade used stand seems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.752</td>\n",
       "      <td>128.780</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>332.27710</td>\n",
       "      <td>36.052360</td>\n",
       "      <td>-137.958185</td>\n",
       "      <td>-37.929113</td>\n",
       "      <td>-40.484483</td>\n",
       "      <td>...</td>\n",
       "      <td>1183.241386</td>\n",
       "      <td>467.201172</td>\n",
       "      <td>733.095629</td>\n",
       "      <td>550.499791</td>\n",
       "      <td>474.172672</td>\n",
       "      <td>290.452405</td>\n",
       "      <td>275.326885</td>\n",
       "      <td>406.844380</td>\n",
       "      <td>2</td>\n",
       "      <td>well train blows whistle pulls away word warni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loudness    tempo  time_signature  key  mode   duration  avg_timbre1  \\\n",
       "0    -7.492  102.750               3    9     1  151.82322    44.942701   \n",
       "1   -14.124   47.873               4    4     1  278.28200    38.694596   \n",
       "2    -7.541  129.161               1    9     1  140.27710    46.470737   \n",
       "3   -13.842  116.031               4    0     1  449.27955    37.471401   \n",
       "4   -13.752  128.780               1    2     1  332.27710    36.052360   \n",
       "\n",
       "   avg_timbre2  avg_timbre3  avg_timbre4  \\\n",
       "0     2.919043    11.452190    -9.939052   \n",
       "1   -57.189799    13.145835   -14.565573   \n",
       "2    72.100780    58.162805     3.429465   \n",
       "3   -17.614596   -20.050936    -1.241322   \n",
       "4  -137.958185   -37.929113   -40.484483   \n",
       "\n",
       "                         ...                          var_timbre5  \\\n",
       "0                        ...                          1002.359830   \n",
       "1                        ...                          1068.480738   \n",
       "2                        ...                           503.012331   \n",
       "3                        ...                           755.294995   \n",
       "4                        ...                          1183.241386   \n",
       "\n",
       "   var_timbre6  var_timbre7  var_timbre8  var_timbre9  var_timbre10  \\\n",
       "0   533.826713   450.342031   371.213158   401.667458    280.375637   \n",
       "1   652.288168   620.755049   472.195177   438.343359    242.868357   \n",
       "2  1061.091441  1244.746517   423.583005   275.888234    257.913246   \n",
       "3  1170.909474   523.003044   510.947644   276.371599    321.595321   \n",
       "4   467.201172   733.095629   550.499791   474.172672    290.452405   \n",
       "\n",
       "   var_timbre11  var_timbre12  Mood  \\\n",
       "0    164.954610    208.439259     3   \n",
       "1    288.765284    339.127532     3   \n",
       "2    302.292429    359.757659     3   \n",
       "3    366.422585    272.122071     2   \n",
       "4    275.326885    406.844380     2   \n",
       "\n",
       "                                              lyrics  \n",
       "0  meet boy like lot fall love loves flame start ...  \n",
       "1  dont know sky blue dont know im love music wou...  \n",
       "2  party ill cry want cry want cry want would cry...  \n",
       "3  day expanding man shape shade used stand seems...  \n",
       "4  well train blows whistle pulls away word warni...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "shuffle(lyrics1)\n",
    "\n",
    "X = lyrics1.lyrics\n",
    "y = lyrics1.Mood\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5835694050991501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.55      0.96      0.70       326\n",
      "           2       1.00      0.04      0.08       126\n",
      "           3       0.72      0.41      0.52       232\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       706\n",
      "   macro avg       0.57      0.35      0.32       706\n",
      "weighted avg       0.67      0.58      0.51       706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5507489004293011]\n",
      "[0.015335286913695196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(nb, lyrics1.lyrics, lyrics1['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.623229461756374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        22\n",
      "           1       0.64      0.83      0.72       326\n",
      "           2       0.54      0.25      0.35       126\n",
      "           3       0.61      0.57      0.59       232\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       706\n",
      "   macro avg       0.70      0.46      0.49       706\n",
      "weighted avg       0.62      0.62      0.60       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6298107345016408]\n",
      "[0.014064695794773173]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(sgd, lyrics1.lyrics, lyrics1['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6345609065155807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        22\n",
      "           1       0.70      0.76      0.73       326\n",
      "           2       0.43      0.43      0.43       126\n",
      "           3       0.64      0.61      0.63       232\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       706\n",
      "   macro avg       0.69      0.50      0.52       706\n",
      "weighted avg       0.64      0.63      0.63       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.668505554459623]\n",
      "[0.02091995270658515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.6s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, lyrics1.lyrics, lyrics1['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.46175637393767704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.46      1.00      0.63       326\n",
      "           2       0.00      0.00      0.00       126\n",
      "           3       0.00      0.00      0.00       232\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       706\n",
      "   macro avg       0.12      0.25      0.16       706\n",
      "weighted avg       0.21      0.46      0.29       706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SVC()),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44751463990637336]\n",
      "[0.0004007936988229333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.2s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, lyrics1.lyrics, lyrics1['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6543909348441926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        22\n",
      "           1       0.66      0.83      0.73       326\n",
      "           2       0.69      0.32      0.43       126\n",
      "           3       0.63      0.64      0.63       232\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       706\n",
      "   macro avg       0.74      0.49      0.53       706\n",
      "weighted avg       0.67      0.65      0.63       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=20)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6667753807419159]\n",
      "[0.018395219748058737]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, lyrics1.lyrics, lyrics1['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5835694050991501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.55      0.96      0.70       326\n",
      "           2       1.00      0.04      0.08       126\n",
      "           3       0.72      0.41      0.52       232\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       706\n",
      "   macro avg       0.57      0.35      0.32       706\n",
      "weighted avg       0.67      0.58      0.51       706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB()),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5507489004293011]\n",
      "[0.015335286913695196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(nb, lyrics1.lyrics, lyrics1['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memorial_Hospital',\n",
       " 'Seniors',\n",
       " 'memorandum',\n",
       " 'elephant',\n",
       " 'Trump',\n",
       " 'Census',\n",
       " 'pilgrims',\n",
       " 'De',\n",
       " 'Dogs',\n",
       " '###-####_ext',\n",
       " 'chaotic',\n",
       " 'forgive',\n",
       " 'scholar',\n",
       " 'Lottery',\n",
       " 'decreasing',\n",
       " 'Supervisor',\n",
       " 'fundamentally',\n",
       " 'Fitness',\n",
       " 'abundance',\n",
       " 'Hold']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "list(islice(wv.vocab, 13030, 13050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "    \n",
    "train, test = train_test_split(lyrics1, test_size=0.3, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['lyrics']), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['lyrics']), axis=1).values\n",
    "\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.46175637393767704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.46      1.00      0.63       326\n",
      "           2       0.00      0.00      0.00       126\n",
      "           3       0.00      0.00      0.00       232\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       706\n",
      "   macro avg       0.12      0.25      0.16       706\n",
      "weighted avg       0.21      0.46      0.29       706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "logreg = SVC()\n",
    "logreg = logreg.fit(X_train_word_average, train['Mood'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.Mood))\n",
    "print(classification_report(test.Mood, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.441411820662982]\n",
      "[0.0010096580227303923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, X_train_word_average, train['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5694050991501416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.23      0.27        22\n",
      "           1       0.64      0.75      0.69       326\n",
      "           2       0.41      0.37      0.39       126\n",
      "           3       0.55      0.47      0.50       232\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       706\n",
      "   macro avg       0.48      0.45      0.46       706\n",
      "weighted avg       0.56      0.57      0.56       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, train['Mood'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.Mood))\n",
    "print(classification_report(test.Mood, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5452123205821757]\n",
      "[0.021923449792399297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, X_train_word_average, train['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6487252124645893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.18      0.30        22\n",
      "           1       0.68      0.81      0.74       326\n",
      "           2       0.52      0.42      0.47       126\n",
      "           3       0.64      0.59      0.62       232\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       706\n",
      "   macro avg       0.66      0.50      0.53       706\n",
      "weighted avg       0.64      0.65      0.64       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "logreg = RandomForestClassifier()\n",
    "logreg = logreg.fit(X_train_word_average, train['Mood'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.Mood))\n",
    "print(classification_report(test.Mood, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6011109134372088]\n",
      "[0.017992441467478255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, X_train_word_average, train['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4631728045325779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.36      0.12        22\n",
      "           1       0.70      0.48      0.57       326\n",
      "           2       0.39      0.21      0.27       126\n",
      "           3       0.44      0.59      0.51       232\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       706\n",
      "   macro avg       0.40      0.41      0.37       706\n",
      "weighted avg       0.54      0.46      0.48       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "logreg = GaussianNB()\n",
    "logreg = logreg.fit(X_train_word_average, train['Mood'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.Mood))\n",
    "print(classification_report(test.Mood, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43238274416721467]\n",
      "[0.034221045680630766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, X_train_word_average, train['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4631728045325779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.36      0.12        22\n",
      "           1       0.70      0.48      0.57       326\n",
      "           2       0.39      0.21      0.27       126\n",
      "           3       0.44      0.59      0.51       232\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       706\n",
      "   macro avg       0.40      0.41      0.37       706\n",
      "weighted avg       0.54      0.46      0.48       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "logreg = GaussianNB()\n",
    "logreg = logreg.fit(X_train_word_average, train['Mood'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.Mood))\n",
    "print(classification_report(test.Mood, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43238274416721467]\n",
      "[0.034221045680630766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, X_train_word_average, train['Mood'], cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "lyrics1['lyrics'] = lyrics1['lyrics'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lyrics1.lyrics, lyrics1.Mood, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['came', 'cold', 'wet', 'drop', 'luggag', 'bag', 'look', 'concierg', 'eye', 'said', 'need', 'room', 'night', 'dont', 'got', 'money', 'would', 'take', 'payment', 'kind', 'said', 'alright', 'got', 'room', 'share', 'mine', 'make', 'bed', 'morn', 'thatll', 'fine', 'chang', 'bathroom', 'hang', 'cloth', 'line', 'tear', 'came', 'eye', 'thought', 'could', 'kind', 'could', 'kind', 'could', 'kind', 'sat', 'bed', 'needl', 'said', 'id', 'hate', 'see', 'bleed', 'ill', 'fetch', 'warm', 'towel', 'sit', 'til', 'your', 'dri', 'start', 'cri', 'say', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'cold', 'turkey', 'hold', 'hand', 'said', 'ruin', 'man', 'never', 'plan', 'dream', 'men', 'love', 'togeth', 'wed', 'see', 'world', 'somehow', 'lost', 'among', 'insult', 'hurl', 'im', 'sure', 'your', 'wonder', 'woman', 'day', 'sure', 'someon', 'relax', 'import', 'your', 'calm', 'said', 'see', 'past', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'see', 'took', 'chanc', 'like', 'place', 'bet', 'sometim', 'reward', 'get', 'alway', 'told', 'see', 'someon', 'defil', 'look', 'eye', 'smile', 'take', 'hand', 'better', 'still', 'take', 'home', 'home', 'home', 'awok', 'earli', 'morn', 'made', 'bed', 'gather', 'cloth', 'leav', 'saw', 'concierg', 'curl', 'sette', 'said', 'hard', 'believ', 'right', 'nobodi', 'know', 'love', 'could', 'leav', 'night', 'help', 'someon', 'bear', 'mind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'consid', 'indiscrimin', 'act', 'kind', 'kind'], tags=['Train_0']),\n",
       " TaggedDocument(words=['surri', 'picnic', 'whoa', 'surri', 'picnic', 'come', 'come', 'surri', 'stone', 'soul', 'picnic', 'surri', 'stone', 'soul', 'picnic', 'surri', 'picnic', 'therel', 'lot', 'time', 'wine', 'red', 'yellow', 'honey', 'sassafra', 'moonshin', 'red', 'yellow', 'honey', 'sassafra', 'moonshin', 'stone', 'soul', 'stone', 'soul', 'whoa', 'come', 'come', 'surri', 'stone', 'soul', 'picnic', 'surri', 'stone', 'soul', 'picnic', 'surri', 'picnic', 'rain', 'sun', 'come', 'sky', 'come', 'lord', 'lightn', 'sky', 'come', 'lord', 'lightn', 'stone', 'soul', 'stone', 'soul', 'surri', 'soul', 'surri', 'surri', 'surri', 'surri', 'therel', 'train', 'blossom', 'therel', 'train', 'blossom', 'therel', 'train', 'music', 'therel', 'music', 'therel', 'train', 'trust', 'train', 'golden', 'dust', 'come', 'along', 'surri', 'sweet', 'train', 'thought', 'surri', 'surri', 'surri', 'surri', 'surri', 'stone', 'soul', 'picnic', 'surri', 'stone', 'soul', 'picnic', 'surri', 'picnic', 'therel', 'lot', 'time', 'wine', 'red', 'yellow', 'honey', 'sassafra', 'moonshin', 'red', 'yellow', 'honey', 'red', 'yellow', 'honey', 'sassafra', 'moonshin', 'moonshin', 'stone', 'soul', 'yeah', 'surri', 'soul', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri', 'surri'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1207980.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 468711.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1364845.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1678149.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2097597.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1394939.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1333134.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1271803.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2459306.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 604915.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2484692.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2609518.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2001053.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2311287.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1324724.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2262020.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1512288.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1166020.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 880942.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1930594.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1556164.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1370531.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 857818.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1973839.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 2441057.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1946587.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1969113.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1284215.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 372085.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1684450.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:00<00:00, 1065672.96it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5240793201133145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.44      0.26        18\n",
      "           1       0.66      0.62      0.64       329\n",
      "           2       0.29      0.34      0.31       119\n",
      "           3       0.55      0.50      0.52       240\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       706\n",
      "   macro avg       0.42      0.47      0.43       706\n",
      "weighted avg       0.55      0.52      0.53       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5300359889202649]\n",
      "[0.012406222303496067]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.6s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, train_vectors_dbow, y_train, cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanth/tf/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6062322946175638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.39      0.52        18\n",
      "           1       0.65      0.76      0.70       329\n",
      "           2       0.46      0.38      0.41       119\n",
      "           3       0.59      0.53      0.56       240\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       706\n",
      "   macro avg       0.62      0.51      0.55       706\n",
      "weighted avg       0.60      0.61      0.60       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = RandomForestClassifier()\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5834579578871224]\n",
      "[0.023674855421877163]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, train_vectors_dbow, y_train, cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6458923512747875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.50      0.41        18\n",
      "           1       0.78      0.71      0.74       329\n",
      "           2       0.48      0.58      0.52       119\n",
      "           3       0.61      0.60      0.60       240\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       706\n",
      "   macro avg       0.55      0.60      0.57       706\n",
      "weighted avg       0.66      0.65      0.65       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = SVC(C=100, degree=3, kernel='rbf', gamma = 'scale')\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.631417878091464]\n",
      "[0.028672460021651365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.4s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, train_vectors_dbow, y_train, cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5070821529745042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.17      0.12        18\n",
      "           1       0.72      0.55      0.63       329\n",
      "           2       0.28      0.42      0.33       119\n",
      "           3       0.51      0.51      0.51       240\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       706\n",
      "   macro avg       0.40      0.41      0.40       706\n",
      "weighted avg       0.56      0.51      0.53       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = GaussianNB()\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5360819028748454]\n",
      "[0.03294614060937076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_scores2 = []\n",
    "scores = cross_val_score(logreg, train_vectors_dbow, y_train, cv=5, scoring = 'accuracy', verbose=True)\n",
    "\n",
    "lr_scores.append(scores.mean())\n",
    "lr_scores2.append(scores.std())\n",
    "\n",
    "print(lr_scores)\n",
    "print(lr_scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bow with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-2759b7458234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTM' is not defined"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "train_size = int(len(lyrics1) * .7)\n",
    "train_posts = lyrics1['lyrics'][:train_size]\n",
    "train_tags = lyrics1['Mood'][:train_size]\n",
    "\n",
    "test_posts = lyrics1['lyrics'][train_size:]\n",
    "test_tags = lyrics1['Mood'][train_size:]\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
